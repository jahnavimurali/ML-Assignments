{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment on PLA with user defined functions\n",
    "\n",
    "- Name: Jahnavi Murali\n",
    "- Reg No.: 3122 21 5001 038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "\n",
    "To develop a python program to make predictions using PLA on the IRIS dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# 150 records with four features each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)\n",
    "# 3 classes: 0, 1, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose two classes for binary classification\n",
    "class1 = 0 \n",
    "class2 = 1  \n",
    "\n",
    "# Filter dataset to keep only samples of the chosen classes\n",
    "X = X[(y == class1) | (y == class2)]\n",
    "y = y[(y == class1) | (y == class2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# 100 records labelled 0 or 1 with 4 features each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron_My:\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, epochs=50):\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    # heaviside activation function\n",
    "    def activation(self, z):\n",
    "      return np.heaviside(z, 0) # haviside(z) heaviside -> activation\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        # Initializing weights and bias\n",
    "        self.weights = np.zeros((n_features))\n",
    "        self.bias = 0\n",
    "\n",
    "        # Iterating until the number of epochs\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            # Traversing through the entire training set\n",
    "            for i in range(len(X)):\n",
    "                z = np.dot(X, self.weights) + self.bias # Finding the dot product and adding the bias\n",
    "                y_pred = self.activation(z) # Passing through an activation function\n",
    "\n",
    "                #Updating weights and bias\n",
    "                self.weights = self.weights + self.learning_rate * (y[i] - y_pred[i]) * X[i]\n",
    "                self.bias = self.bias + self.learning_rate * (y[i] - y_pred[i])\n",
    "\n",
    "        return self.weights, self.bias\n",
    "    \n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return self.activation(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron_My()\n",
    "perceptron.fit(X_train, y_train)\n",
    "pred = perceptron.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(pred, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can infer from the above results that PLA performs well in iris dataset with 100%\n",
    "accuracy\n",
    "- Even though Perceptrons are considered great by researchers, they also find some limitations, first of all, it is a binary classifier, so they cannot be used for learning really complex data like natural language processing, speech recognition, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understood and implemented the concept of PLA .\n",
    "- Understood and implemented user defined custom designed models for PLA and\n",
    "compared the results with the built in functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
